#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æŠ•ç¨¿å†…å®¹ã‚’ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
å®Ÿéš›ã«Discordã«æŠ•ç¨¿ã›ãšã«ã€æŠ•ç¨¿ã•ã‚Œã‚‹å†…å®¹ã‚’ç¢ºèªã§ãã¾ã™
"""

import sys
from pathlib import Path
from datetime import datetime

# tenkaippin_bot.pyã‹ã‚‰å¿…è¦ãªã‚¯ãƒ©ã‚¹ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
sys.path.insert(0, str(Path(__file__).parent))
from tenkaippin_bot import (
    TenkaippinCrawler, 
    HistoryManager, 
    HISTORY_FILE, 
    HISTORY_RETENTION_DAYS,
    DAYS_TO_CHECK
)
from dotenv import load_dotenv
import discord

# ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
load_dotenv()

def preview_embed(store_info):
    """Embedã®å†…å®¹ã‚’ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼è¡¨ç¤º"""
    embed = discord.Embed(
        title="æ±äº¬ã«å¤©ä¸‹ä¸€å“ãŒã‚ªãƒ¼ãƒ—ãƒ³ã™ã‚‹ã‚ˆï¼",
        description=store_info['title'],
        url=store_info['url'],
        color=discord.Color.orange(),
        timestamp=datetime.now()
    )
    embed.add_field(name="è¨˜äº‹æ—¥ä»˜", value=store_info['date'], inline=True)
    
    # ã‚ªãƒ¼ãƒ—ãƒ³æ—¥ãŒã‚ã‚‹å ´åˆã¯è¡¨ç¤º
    opening_date = store_info.get('opening_date')
    if opening_date:
        embed.add_field(name="ã‚ªãƒ¼ãƒ—ãƒ³æ—¥", value=opening_date, inline=True)
    
    embed.add_field(name="è©³ç´°", value=f"[è¨˜äº‹ã‚’èª­ã‚€]({store_info['url']})", inline=True)
    
    # Embedã®å†…å®¹ã‚’ãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ã§è¡¨ç¤º
    print("=" * 60)
    print("ğŸ“‹ DiscordæŠ•ç¨¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
    print("=" * 60)
    print(f"\nã€ã‚¿ã‚¤ãƒˆãƒ«ã€‘")
    print(embed.title)
    print(f"\nã€èª¬æ˜æ–‡ã€‘")
    print(embed.description)
    print(f"\nã€URLã€‘")
    print(embed.url)
    print(f"\nã€ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã€‘")
    for field in embed.fields:
        print(f"  {field.name}: {field.value}")
    print(f"\nã€ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã€‘")
    print(embed.timestamp)
    print("=" * 60)
    print()

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("å¤©ä¸‹ä¸€å“ãƒ‹ãƒ¥ãƒ¼ã‚¹å–å¾—ä¸­...")
    
    crawler = TenkaippinCrawler()
    history_manager = HistoryManager(HISTORY_FILE, HISTORY_RETENTION_DAYS)
    
    # ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å–å¾—
    news_items = crawler.fetch_news()
    
    if not news_items:
        print("âŒ ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
        return
    
    # ç›´è¿‘Næ—¥ä»¥å†…ã®è¨˜äº‹ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    from datetime import datetime, timedelta
    cutoff_date = datetime.now() - timedelta(days=DAYS_TO_CHECK)
    recent_news = []
    
    for item in news_items:
        date_str = item.get('date', '')
        try:
            item_date = datetime.strptime(date_str, '%Y-%m-%d')
            if item_date >= cutoff_date:
                recent_news.append(item)
        except (ValueError, TypeError):
            continue
    
    print(f"âœ… {len(recent_news)}ä»¶ã®ç›´è¿‘{DAYS_TO_CHECK}æ—¥ä»¥å†…ã®è¨˜äº‹ã‚’å–å¾—\n")
    
    # éƒ½å†…ã®æ–°åº—æƒ…å ±ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    tokyo_stores = []
    for item in recent_news:
        if crawler.is_tokyo_store(item):
            # ã‚ªãƒ¼ãƒ—ãƒ³æ—¥ãŒã¾ã æŠ½å‡ºã•ã‚Œã¦ã„ãªã„å ´åˆã€è©³ç´°ãƒšãƒ¼ã‚¸ã‹ã‚‰æŠ½å‡º
            if 'opening_date' not in item:
                url = item.get('url')
                if url and url != "https://www.tenkaippin.co.jp/news/":
                    detail_text = crawler.fetch_article_detail(url)
                    if detail_text:
                        opening_date = crawler.extract_opening_date(detail_text)
                        if opening_date:
                            item['opening_date'] = opening_date
                            print(f"âœ… ã‚ªãƒ¼ãƒ—ãƒ³æ—¥ã‚’æŠ½å‡º: {opening_date}")
            
            # æŠ•ç¨¿å±¥æ­´ã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ãªã®ã§å®Ÿéš›ã«ã¯æŠ•ç¨¿ã—ãªã„ï¼‰
            if not history_manager.is_posted(item):
                tokyo_stores.append(item)
    
    if not tokyo_stores:
        print("éƒ½å†…ã®æ–°åº—æƒ…å ±ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        return
    
    print(f"\nâœ… {len(tokyo_stores)}ä»¶ã®éƒ½å†…æ–°åº—æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ\n")
    
    # å„è¨˜äº‹ã®æŠ•ç¨¿å†…å®¹ã‚’ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
    for i, store_info in enumerate(tokyo_stores, 1):
        print(f"\nã€è¨˜äº‹ {i}/{len(tokyo_stores)}ã€‘")
        preview_embed(store_info)
        
        if i < len(tokyo_stores):
            print("\n" + "-" * 60 + "\n")

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ãŒä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
    except Exception as e:
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc()


